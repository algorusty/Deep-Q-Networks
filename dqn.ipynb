{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.20s/it]\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wesle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"fblgit/juanako-7b-UNA\"\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    # low_cpu_mem_usage=True,\n",
    "    # device_map=\"cuda:0\"\n",
    ")\n",
    "# Create the tokenizer from the model object\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "# print(llm(\"AI is going to\"))\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: <s> the quick brown fox jumps over buchan\n",
      "Fluency: 0.054166666666666696, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.13848591339324035, Total: 0.05784037663671318\n",
      "Action: tensor([22699]), Reward: 0.05784037663671318, Total Reward: 0.05784037663671318\n",
      "Sequence: <s> the quick brown fox jumps over buch거n\n",
      "Fluency: 0.05384615384615388, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.11847582534427681, Total: 0.06768516425093854\n",
      "Action: tensor([30013]), Reward: 0.06768516425093854, Total Reward: 0.12552554088765172\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils\n",
      "\n",
      "Fluency: 0.050000000000000044, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.11905108012302612, Total: 0.06547445993848697\n",
      "Action: tensor([4544]), Reward: 0.06547445993848697, Total Reward: 0.1910000008261387\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter\n",
      "\n",
      "Fluency: 0.050000000000000044, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.1089907549327751, Total: 0.07050462253361248\n",
      "Action: tensor([12872]), Reward: 0.07050462253361248, Total Reward: 0.26150462335975116\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调查\n",
      "Fluency: 0.05312500000000009, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.10581769214414694, Total: 0.07365365392792658\n",
      "Action: tensor([29231]), Reward: 0.07365365392792658, Total Reward: 0.3351582772876778\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调alex\n",
      "Fluency: 0.05294117647058827, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.10165907663156204, Total: 0.07564104991951312\n",
      "Action: tensor([282]), Reward: 0.07564104991951312, Total Reward: 0.4107993272071909\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调al Heavenly\n",
      "Fluency: 0.05277777777777781, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.09948048261466202, Total: 0.0766486475815579\n",
      "Action: tensor([22830]), Reward: 0.0766486475815579, Total Reward: 0.4874479747887488\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调al Heavencourt \n",
      "Fluency: 0.050000000000000044, Relevance: 0.0, Diversity: 0.981637513409912, Perplexity: -0.10370558675508912, Total: 0.07131095796344666\n",
      "Action: tensor([28129]), Reward: 0.07131095796344666, Total Reward: 0.5587589327521955\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调al Heavencourt}, the\n",
      "Fluency: 0.05500000000000016, Relevance: 0.0, Diversity: 0.9828778776927556, Perplexity: -0.10141831395621426, Total: 0.0750786307911685\n",
      "Action: tensor([881]), Reward: 0.0750786307911685, Total Reward: 0.633837563543364\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调al Heavencourt}, Dr.\n",
      "Fluency: 0.05476190476190479, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.10269170700146568, Total: 0.07603509888021956\n",
      "Action: tensor([2985]), Reward: 0.07603509888021956, Total Reward: 0.7098726624235835\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调al Heavencourt}, Dr공�\n",
      "Fluency: 0.05454545454545445, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.09558846690979972, Total: 0.07947849381782737\n",
      "Action: tensor([30010]), Reward: 0.07947849381782737, Total Reward: 0.7893511562414108\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调al Heavencourt}, Dr공ometry,\n",
      "Fluency: 0.05434782608695654, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.09780642695127639, Total: 0.07827069956784008\n",
      "Action: tensor([8289]), Reward: 0.07827069956784008, Total Reward: 0.8676218558092509\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调al Heavencourt}, Dr공ometryoux,\n",
      "Fluency: 0.054166666666666696, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.0968020884449784, Total: 0.07868228911084416\n",
      "Action: tensor([20149]), Reward: 0.07868228911084416, Total Reward: 0.9463041449200951\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调al Heavencourt}, Dr공ometryouxborn,\n",
      "Fluency: 0.053999999999999826, Relevance: 0.0, Diversity: 1.0, Perplexity: -0.09593605772794767, Total: 0.07903197113602609\n",
      "Action: tensor([6363]), Reward: 0.07903197113602609, Total Reward: 1.0253361160561212\n",
      "Sequence: <s> the quick brown fox jumps over buch거ils underarter调al Heavencourt}, Dr공ometryouxborn seeing the\n",
      "Fluency: 0.05384615384615388, Relevance: 0.0, Diversity: 0.9879620776439304, Perplexity: -0.09469794174994561, Total: 0.07837031381249718\n",
      "Action: tensor([6252]), Reward: 0.07837031381249718, Total Reward: 1.1037064298686183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes:   0%|          | 0/100 [04:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wesle\\Github\\qualia\\Deep-Q-Networks\\dqn.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=222'>223</a>\u001b[0m dqn_agent \u001b[39m=\u001b[39m DQNAgent(state_size, action_size, hidden_size, learning_rate, gamma)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=223'>224</a>\u001b[0m llm_dqn \u001b[39m=\u001b[39m LLMDQN(model, dqn_agent, tokenizer)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=225'>226</a>\u001b[0m train(llm_dqn, dqn_agent, num_episodes\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, target_context\u001b[39m=\u001b[39;49mtarget_context)\n",
      "\u001b[1;32mc:\\Users\\wesle\\Github\\qualia\\Deep-Q-Networks\\dqn.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=192'>193</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m     action \u001b[39m=\u001b[39m dqn_agent\u001b[39m.\u001b[39mselect_action(input_ids)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=194'>195</a>\u001b[0m     next_input_ids, reward, done \u001b[39m=\u001b[39m environment_step(llm_dqn\u001b[39m.\u001b[39;49mmodel, input_ids, action)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=195'>196</a>\u001b[0m     dqn_agent\u001b[39m.\u001b[39mupdate(input_ids, action, reward, next_input_ids, done)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=196'>197</a>\u001b[0m     input_ids \u001b[39m=\u001b[39m next_input_ids\n",
      "\u001b[1;32mc:\\Users\\wesle\\Github\\qualia\\Deep-Q-Networks\\dqn.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m input_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((input_ids, torch\u001b[39m.\u001b[39mtensor([[action]])), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39;49minput_ids)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m logits \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlogits\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/wesle/Github/qualia/Deep-Q-Networks/dqn.ipynb#W2sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m next_token_id \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(logits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1009\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1006\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m   1008\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[0;32m   1010\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1011\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1012\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1013\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1014\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1015\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1016\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1017\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1018\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[0;32m   1021\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1022\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:897\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    887\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    888\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[0;32m    889\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    894\u001b[0m         use_cache,\n\u001b[0;32m    895\u001b[0m     )\n\u001b[0;32m    896\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 897\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[0;32m    898\u001b[0m         hidden_states,\n\u001b[0;32m    899\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    900\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m    901\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m    902\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    903\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    904\u001b[0m     )\n\u001b[0;32m    906\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    908\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:639\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m    638\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m--> 639\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[0;32m    640\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n\u001b[0;32m    642\u001b[0m outputs \u001b[39m=\u001b[39m (hidden_states,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:175\u001b[0m, in \u001b[0;36mMistralMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown_proj(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgate_proj(x)) \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mup_proj(x))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "class DQNNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size):\n",
    "        super(DQNNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, hidden_size, learning_rate, gamma):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = DQNNetwork(state_size, action_size, hidden_size)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = state.float()\n",
    "        state_tensor = pad_or_truncate(state, max_length=512)\n",
    "        state_tensor = state_tensor.unsqueeze(0)  # Ensure it has a batch dimension\n",
    "\n",
    "        if random.random() <= self.epsilon:\n",
    "            return torch.tensor([random.randrange(self.action_size)], dtype=torch.long)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = self.model(state_tensor)\n",
    "            return torch.tensor([np.argmax(q_values.cpu().detach().numpy())], dtype=torch.long)\n",
    "\n",
    "\n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        state = pad_or_truncate(state, max_length=512).float()\n",
    "        next_state = pad_or_truncate(next_state, max_length=512).float()\n",
    "\n",
    "        reward = torch.tensor(reward, dtype=torch.float)\n",
    "        done = torch.tensor(done, dtype=torch.float)\n",
    "\n",
    "        # Compute Q values for current and next state\n",
    "        q_values = self.model(state)\n",
    "        q_next = self.model(next_state).detach()\n",
    "\n",
    "        # Compute the expected Q values\n",
    "        q_update = reward + self.gamma * q_next.max(1)[0] * (1 - done)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(q_values.gather(1, action.unsqueeze(1)), q_update.unsqueeze(1))\n",
    "\n",
    "        # Backpropagation\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Epsilon decay\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "def environment_step(model, input_ids, action):\n",
    "    input_ids = torch.cat((input_ids, torch.tensor([[action]])), dim=1)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "    logits = outputs.logits\n",
    "    next_token_id = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(0)\n",
    "    reward = compute_reward(input_ids, next_token_id)\n",
    "    done = next_token_id.item() == tokenizer.eos_token_id\n",
    "    return input_ids, reward, done\n",
    "\n",
    "def compute_perplexity(sequence):\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    # Perplexity is e^loss\n",
    "    perplexity = torch.exp(outputs.loss)\n",
    "    return 1 / (1 + np.log(perplexity.item() + 1))\n",
    "\n",
    "def compute_reward(input_ids, next_token_id, target_context_embedding=None):\n",
    "    \"\"\" Compute the reward for the generated sequence. \"\"\"\n",
    "    input_ids = input_ids.flatten()\n",
    "    next_token_id = next_token_id.item() if isinstance(next_token_id, torch.Tensor) else next_token_id\n",
    "    sequence_tokens = input_ids.tolist() + [next_token_id]\n",
    "    \n",
    "    # Decode the sequence tokens into a sentence and print it\n",
    "    sequence_sentence = tokenizer.decode(sequence_tokens)\n",
    "    print(f\"Sequence: {sequence_sentence}\")\n",
    "    \n",
    "    fluency_reward = compute_fluency(sequence_tokens)\n",
    "    relevance_reward = 0\n",
    "    if target_context_embedding is not None:\n",
    "        sequence_embedding = compute_embeddings(tokenizer.decode(sequence_tokens))\n",
    "        relevance_reward = compute_relevance(sequence_embedding, target_context_embedding)\n",
    "    diversity_reward = lexical_diversity(sequence_tokens)\n",
    "    perplexity_reward = -compute_perplexity(tokenizer.decode(sequence_tokens))\n",
    "    fluency_reward = normalize_reward(fluency_reward)\n",
    "    relevance_reward = normalize_reward(relevance_reward)\n",
    "    diversity_reward = normalize_reward(diversity_reward)\n",
    "    perplexity_reward = normalize_reward(perplexity_reward)\n",
    "    weights = {'fluency': 0.5, 'relevance': 0.1, 'diversity': 0.1, 'perplexity': 0.7}\n",
    "    total_reward = (weights['fluency'] * fluency_reward + \n",
    "                    weights['relevance'] * relevance_reward +\n",
    "                    weights['diversity'] * diversity_reward + \n",
    "                    weights['perplexity'] * perplexity_reward)\n",
    "    print(f\"Fluency: {fluency_reward}, Relevance: {relevance_reward}, Diversity: {diversity_reward}, Perplexity: {perplexity_reward}, Total: {total_reward}\")\n",
    "\n",
    "    return total_reward\n",
    "\n",
    "def normalize_reward(reward, min_reward=-1, max_reward=1):\n",
    "    # Normalize reward to be within [min_reward, max_reward]\n",
    "    return (reward - min_reward) / (max_reward - min_reward) * 2 - 1\n",
    "\n",
    "def compute_fluency(tokens):\n",
    "    sentences = [tokenizer.decode(sentence_tokens) for sentence_tokens in tokens]\n",
    "    total_words = sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
    "    num_sentences = len(sentences)\n",
    "    avg_sentence_length = total_words / num_sentences if num_sentences > 0 else 0\n",
    "\n",
    "    # Define the ideal sentence length\n",
    "    ideal_sentence_length = 20\n",
    "\n",
    "    # Calculate the fluency score based on how close the average sentence length is to the ideal length\n",
    "    fluency_score = 1 - abs(avg_sentence_length - ideal_sentence_length) / ideal_sentence_length\n",
    "\n",
    "    # Ensure the fluency score is between 0 and 1\n",
    "    fluency_score = max(0, min(fluency_score, 1))\n",
    "\n",
    "    return fluency_score\n",
    "\n",
    "import math\n",
    "\n",
    "def lexical_diversity(tokens):\n",
    "    words = [tokenizer.decode(token) for token in tokens]\n",
    "    unique_words = set(words)\n",
    "    num_types = len(unique_words)\n",
    "    num_tokens = len(words)\n",
    "    \n",
    "    if num_tokens > 0 and num_types > 0:\n",
    "        herdan_c = math.log(num_types) / math.log(num_tokens)\n",
    "    else:\n",
    "        herdan_c = 0\n",
    "\n",
    "    return herdan_c\n",
    "\n",
    "def compute_relevance(sequence_embedding, target_context_embedding):\n",
    "    cosine_similarity = torch.nn.functional.cosine_similarity(sequence_embedding, target_context_embedding)\n",
    "    return cosine_similarity.item()\n",
    "\n",
    "def compute_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "class LLMDQN:\n",
    "    def __init__(self, model, dqn_agent, tokenizer):\n",
    "        self.model = model\n",
    "        self.dqn_agent = dqn_agent\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def generate_sequence(self, prompt):\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors='pt')\n",
    "        generated_sequence = []\n",
    "        while not self.end_condition_met(input_ids):\n",
    "            action = self.dqn_agent.select_action(input_ids)\n",
    "            input_ids, reward = environment_step(self.model, input_ids, action)\n",
    "            self.dqn_agent.update(input_ids, action, reward, input_ids)\n",
    "            generated_sequence.append(action)\n",
    "        return self.tokenizer.decode(generated_sequence)\n",
    "\n",
    "    def end_condition_met(self, input_ids, max_length=50):\n",
    "        return (input_ids[-1] == tokenizer.eos_token_id) or (input_ids.size(1) > max_length)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(llm_dqn, dqn_agent, num_episodes, target_context):\n",
    "    for episode in tqdm(range(num_episodes), desc=\"Training Episodes\"):\n",
    "        input_ids = tokenizer.encode(target_context, return_tensors='pt')\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = dqn_agent.select_action(input_ids)\n",
    "            next_input_ids, reward, done = environment_step(llm_dqn.model, input_ids, action)\n",
    "            dqn_agent.update(input_ids, action, reward, next_input_ids, done)\n",
    "            input_ids = next_input_ids\n",
    "            total_reward += reward\n",
    "            print(f\"Action: {action}, Reward: {reward}, Total Reward: {total_reward}\")\n",
    "            if done:\n",
    "                print(f\"Episode {episode + 1} Complete. Total Reward: {total_reward}\")\n",
    "                print(f\"Generated Sequence: {llm_dqn.generate_sequence(target_context)}\\n\")\n",
    "\n",
    "\n",
    "def pad_or_truncate(sequence, max_length=512, pad_token_id=0):\n",
    "    sequence = sequence.view(-1)\n",
    "    sequence_length = sequence.size(0)\n",
    "    if sequence_length > max_length:\n",
    "        return sequence[:max_length].unsqueeze(0)\n",
    "    elif sequence_length < max_length:\n",
    "        padding = torch.full((max_length - sequence_length,), pad_token_id, dtype=sequence.dtype)\n",
    "        return torch.cat((sequence, padding), dim=0).unsqueeze(0)\n",
    "    else:\n",
    "        return sequence.unsqueeze(0)\n",
    "\n",
    "state_size = 512\n",
    "action_size = tokenizer.vocab_size\n",
    "hidden_size = 128\n",
    "learning_rate = 0.001\n",
    "gamma = 0.99\n",
    "target_context = \"the quick brown fox jumps over \"\n",
    "\n",
    "dqn_agent = DQNAgent(state_size, action_size, hidden_size, learning_rate, gamma)\n",
    "llm_dqn = LLMDQN(model, dqn_agent, tokenizer)\n",
    "\n",
    "train(llm_dqn, dqn_agent, num_episodes=100, target_context=target_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU support) is not available in PyTorch.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA (GPU support) is available in PyTorch!\")\n",
    "    print(\"Number of GPU devices available:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA (GPU support) is not available in PyTorch.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
